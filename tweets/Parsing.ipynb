{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Combine original datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets: 4066\n"
     ]
    }
   ],
   "source": [
    "with open('master_2019.txt', 'r', encoding='utf-8') as f:\n",
    "    data_2019 = f.readlines()\n",
    "    tweets_2019 = [tweet.rstrip('\\n') for tweet in data_2019[1:]]\n",
    "    # Remove tweets with 'Thank you'\n",
    "    tweets_2019 = [tweet for tweet in tweets_2019 if 'Thank you' not in tweet]\n",
    "    print(\"No. of tweets:\", len(tweets_2019))\n",
    "    \n",
    "del data_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets: 2281\n"
     ]
    }
   ],
   "source": [
    "with open('master_2018.json') as f:\n",
    "    data_2018 = json.load(f)\n",
    "    \n",
    "tweets_2018 = []\n",
    "for tweet in reversed(data_2018):\n",
    "    if tweet['retweeted']==False:\n",
    "        if 'android' in tweet['source']:\n",
    "            try:\n",
    "                tweets_2018.append(tweet['full_text'])\n",
    "            except:\n",
    "                tweets_2018.append(tweet['text'])\n",
    "        elif 'iphone' in tweet['source']:\n",
    "            try:\n",
    "                if 'Thank you' not in tweet['text']:\n",
    "                    tweets_2018.append(tweet['text'])\n",
    "            except:\n",
    "                if 'Thank you' not in tweet['full_text']:\n",
    "                    tweets_2018.append(tweet['full_text'])\n",
    "            \n",
    "del data_2018\n",
    "print(\"No. of tweets:\", len(tweets_2018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets: 2281\n"
     ]
    }
   ],
   "source": [
    "with open('master_2017.json') as f:\n",
    "    data_2017 = json.load(f)\n",
    "    \n",
    "tweets_2017 = []\n",
    "for tweet in reversed(data_2017):\n",
    "    if tweet['retweeted']==False:\n",
    "        if 'android' in tweet['source']:\n",
    "            try:\n",
    "                tweets_2017.append(tweet['full_text'])\n",
    "            except:\n",
    "                tweets_2017.append(tweet['text'])\n",
    "        elif 'iphone' in tweet['source']:\n",
    "            try:\n",
    "                if 'Thank you' not in tweet['text']:\n",
    "                    tweets_2017.append(tweet['text'])\n",
    "            except:\n",
    "                if 'Thank you' not in tweet['full_text']:\n",
    "                    tweets_2017.append(tweet['full_text'])\n",
    "del data_2017\n",
    "print(\"No. of tweets:\", len(tweets_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets: 3361\n"
     ]
    }
   ],
   "source": [
    "with open('master_2016.json') as f:\n",
    "    data_2016 = json.load(f)\n",
    "    \n",
    "tweets_2016 = []\n",
    "for tweet in reversed(data_2016):\n",
    "    if tweet['retweeted']==False:\n",
    "        if 'android' in tweet['source']:\n",
    "            try:\n",
    "                tweets_2016.append(tweet['full_text'])\n",
    "            except:\n",
    "                tweets_2016.append(tweet['text'])\n",
    "        elif 'iphone' in tweet['source']:\n",
    "            try:\n",
    "                if 'Thank you' not in tweet['text']:\n",
    "                    tweets_2016.append(tweet['text'])\n",
    "            except:\n",
    "                if 'Thank you' not in tweet['full_text']:\n",
    "                    tweets_2016.append(tweet['full_text'])\n",
    "            \n",
    "del data_2016\n",
    "print(\"No. of tweets:\", len(tweets_2016))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets: 7124\n"
     ]
    }
   ],
   "source": [
    "with open('master_2015.json') as f:\n",
    "    data_2015 = json.load(f)\n",
    "    \n",
    "tweets_2015 = []\n",
    "for tweet in reversed(data_2015):\n",
    "    if (tweet['retweeted']==False) and ('iphone' not in tweet['source']):\n",
    "        try:\n",
    "            tweets_2015.append(tweet['full_text'])\n",
    "        except:\n",
    "            tweets_2015.append(tweet['text'])\n",
    "            \n",
    "del data_2015\n",
    "print(\"No. of tweets:\", len(tweets_2015))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets: 5781\n"
     ]
    }
   ],
   "source": [
    "with open('master_2014.json') as f:\n",
    "    data_2014 = json.load(f)\n",
    "    \n",
    "tweets_2014 = []\n",
    "for tweet in reversed(data_2014):\n",
    "    if (tweet['retweeted']==False) and ('iphone' not in tweet['source']):\n",
    "        try:\n",
    "            tweets_2014.append(tweet['full_text'])\n",
    "        except:\n",
    "            tweets_2014.append(tweet['text'])\n",
    "            \n",
    "del data_2014\n",
    "print(\"No. of tweets:\", len(tweets_2014))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets: 8135\n"
     ]
    }
   ],
   "source": [
    "with open('master_2013.json') as f:\n",
    "    data_2013 = json.load(f)\n",
    "    \n",
    "tweets_2013 = []\n",
    "for tweet in reversed(data_2013):\n",
    "    if tweet['retweeted']==False:\n",
    "        try:\n",
    "            tweets_2013.append(tweet['full_text'])\n",
    "        except:\n",
    "            tweets_2013.append(tweet['text'])\n",
    "            \n",
    "del data_2013\n",
    "print(\"No. of tweets:\", len(tweets_2013))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets: 3529\n"
     ]
    }
   ],
   "source": [
    "with open('master_2012.json') as f:\n",
    "    data_2012 = json.load(f)\n",
    "    \n",
    "tweets_2012 = []\n",
    "for tweet in reversed(data_2012):\n",
    "    if tweet['retweeted']==False:\n",
    "        try:\n",
    "            tweets_2012.append(tweet['full_text'])\n",
    "        except:\n",
    "            tweets_2012.append(tweet['text'])\n",
    "            \n",
    "del data_2012\n",
    "print(\"No. of tweets:\", len(tweets_2012))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets: 774\n"
     ]
    }
   ],
   "source": [
    "with open('master_2011.json') as f:\n",
    "    data_2011 = json.load(f)\n",
    "    \n",
    "tweets_2011 = []\n",
    "for tweet in reversed(data_2011):\n",
    "    if tweet['retweeted']==False:\n",
    "        try:\n",
    "            tweets_2011.append(tweet['full_text'])\n",
    "        except:\n",
    "            tweets_2011.append(tweet['text'])\n",
    "            \n",
    "del data_2011\n",
    "print(\"No. of tweets:\", len(tweets_2011))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets: 142\n"
     ]
    }
   ],
   "source": [
    "with open('master_2010.json') as f:\n",
    "    data_2010 = json.load(f)\n",
    "    \n",
    "tweets_2010 = []\n",
    "for tweet in reversed(data_2010):\n",
    "    if tweet['retweeted']==False:\n",
    "        try:\n",
    "            tweets_2010.append(tweet['full_text'])\n",
    "        except:\n",
    "            tweets_2010.append(tweet['text'])\n",
    "            \n",
    "del data_2010\n",
    "print(\"No. of tweets:\", len(tweets_2010))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets: 56\n"
     ]
    }
   ],
   "source": [
    "with open('master_2009.json') as f:\n",
    "    data_2009 = json.load(f)\n",
    "    \n",
    "tweets_2009 = []\n",
    "for tweet in reversed(data_2009):\n",
    "    if tweet['retweeted']==False:\n",
    "        try:\n",
    "            tweets_2009.append(tweet['full_text'])\n",
    "        except:\n",
    "            tweets_2009.append(tweet['text'])\n",
    "            \n",
    "del data_2009\n",
    "print(\"No. of tweets:\", len(tweets_2009))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tweets = tweets_2009 + tweets_2010 + tweets_2011 + tweets_2012 + tweets_2013 + tweets_2014 + tweets_2015 + tweets_2016 + tweets_2017 + tweets_2018 + tweets_2019\n",
    "tweets = [tweet for tweet in tweets if 'RT @' not in tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36699"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('tweets.json', 'w') as outfile:\n",
    "    json.dump(tweets, outfile)\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweets.json') as f:\n",
    "    tweets = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets with announcement words: 5968\n",
      "No. of manual RTs: 5847\n",
      "Dataset: 20952\n"
     ]
    }
   ],
   "source": [
    "# Convert &amp to &\n",
    "tweets_2 = []\n",
    "for tweet in tweets:\n",
    "    if '&amp' in tweet:\n",
    "        tweets_2.append(''.join(tweet.split('amp;')))\n",
    "    else:\n",
    "        tweets_2.append(tweet)\n",
    "        \n",
    "# convert \\u201 to '\n",
    "tweets_3 = []\n",
    "for tweet in tweets_2:\n",
    "    if '\\\\u2013' in tweet:\n",
    "        tweets_3.append('\\''.join(tweet.split('\\\\u2013')))\n",
    "    if '\\\\u2015' in tweet:\n",
    "        tweets_3.append('\\''.join(tweet.split('\\\\u2015')))\n",
    "    if '\\\\u2018' in tweet:\n",
    "        tweets_3.append('\\''.join(tweet.split('\\\\u2018')))\n",
    "    if '\\\\u2019' in tweet:\n",
    "        tweets_3.append('\\''.join(tweet.split('\\\\u2019')))\n",
    "    else:\n",
    "        tweets_3.append(tweet)\n",
    "        \n",
    "# Get rid of URLs\n",
    "tweets_4 = []\n",
    "for tweet in tweets_3:\n",
    "    if 'http' in tweet:\n",
    "        tweets_4.append(''.join(re.split(r'http\\S+', tweet)))\n",
    "    else:\n",
    "        tweets_4.append(tweet)\n",
    "        \n",
    "# Get rid of '[VIDEO]', 'Video'\n",
    "tweets_5 = [tweet for tweet in tweets_4 if ('[VIDEO]' not in tweet) and ('Video' not in tweet)]\n",
    "        \n",
    "# Get rid of tweets with more than 3 twitter handles (1247)\n",
    "tweets_6 = []\n",
    "for tweet in tweets_5:\n",
    "    if tweet.count('@') <= 2:\n",
    "        tweets_6.append(tweet)\n",
    "\n",
    "# Get rid of tweets for event announcements with words like 'join', 'Join', 'tomorrow' and hashtags\n",
    "count_announcements = 0\n",
    "tweets_7 = []\n",
    "for tweet in tweets_6:\n",
    "    if ('join' in tweet) or ('Join' in tweet) or ('tomorrow' in tweet) or ('Tune' in tweet) or ('I\\'ll be on' in tweet) or \\\n",
    "    ('#Take' in tweet) or ('Just arrive' in tweet) or ('#trump' in tweet) or (' EST ' in tweet) or ('AM ' in tweet) or \\\n",
    "    ('My interview' in tweet) or ('trump2016' in tweet) or ('My @FoxNews' in tweet) or ('I will be on' in tweet) or \\\n",
    "    ('makeamerica' in tweet) or ('#INP' in tweet) or ('I will be interviewed' in tweet) or ('I will be going' in tweet) or \\\n",
    "    ('I will be making' in tweet) or ('I will be in' in tweet) or ('I will be li' in tweet) or ('I will be do' in tweet) or \\\n",
    "    ('#TrumpTu' in tweet) or ('#TrumpTr' in tweet) or ('Thanks.' in tweet) or ('Thanks!' in tweet) or ('thanks!' in tweet) or \\\n",
    "    ('thanks.' in tweet) or ('Via' in tweet) or ('via' in tweet) or ('P.M' in tweet) or ('A.M' in tweet) or \\\n",
    "    ('Will be on ' in tweet) or ('Will be interv' in tweet) or ('#El' in tweet) or ('#IC' in tweet) or ('#IA' in tweet) or \\\n",
    "    ('Looking' in tweet) or ('Watch m' in tweet) or ('My @g' in tweet) or ('My @' in tweet) or ('Had a g' in tweet) or \\\n",
    "    ('ICYMI' in tweet) or ('do you think s' in tweet) or ('\\\"@real' in tweet) or ('On my' in tweet) or \\\n",
    "    ('Today' in tweet[:6]) or ('Vote ' in tweet[:6]) or ((len(tweet)<23 and ('WITCH' not in tweet) and \\\n",
    "                                                          ('MAGA' not in tweet) and ('Merr' not in tweet) and \\\n",
    "                                                          ('MERRY' not in tweet) and ('loser' not in tweet))) or \\\n",
    "    ('Be sure' in tweet[:7]) or ('was a great honor' in tweet) or ('was my great honor' in tweet[:21]) or \\\n",
    "    ('Watch @' in tweet[:8]) or ('Watch ' in tweet[:8] and 'M' in tweet) or ('@' in tweet and len(tweet)<40) or \\\n",
    "    ('#Trump2' in tweet and '\\\"' in tweet[0]) or ('Tonight' in tweet[:7]) or ('Celebrity' in tweet[:11]) or \\\n",
    "    ('Don\\'t forget' in tweet[:13]) or ('Celebrity Apprentice' in tweet[:40]) or ('#As' in tweet) or ('#Vote' in tweet):\n",
    "        count_announcements+=1\n",
    "    else:\n",
    "        tweets_7.append(tweet)\n",
    "print('No. of tweets with announcement words:', count_announcements)\n",
    "\n",
    "# Get rid of manual retweets @XXX: @realDonaldTrump\n",
    "manual_retweets = 0\n",
    "tweets_8 = []\n",
    "for tweet in tweets_7:\n",
    "    try:\n",
    "        re.search(r'@\\S+:\\s@\\S+', tweet).group(0)\n",
    "        manual_retweets+=1\n",
    "    except:\n",
    "        tweets_8.append(tweet)\n",
    "        \n",
    "# Get rid of manual retweets \"@XXX: \"\n",
    "tweets_9 = []\n",
    "for tweet in tweets_8:\n",
    "    try:\n",
    "        re.search(r'\\\"@\\S+:\\s', tweet).group(0)\n",
    "        manual_retweets+=1\n",
    "    except:\n",
    "        tweets_9.append(tweet)\n",
    "        \n",
    "# Get rid of manual retweets \"@XXX @realDonaldTrump \"\n",
    "tweets_10 = []\n",
    "for tweet in tweets_9:\n",
    "    try:\n",
    "        re.search(r'\\\"@\\S+\\s+@r', tweet).group(0)\n",
    "        manual_retweets+=1\n",
    "    except:\n",
    "        tweets_10.append(tweet)\n",
    "        \n",
    "print('No. of manual RTs:', manual_retweets)\n",
    "\n",
    "print('Dataset:', len(tweets_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2922774"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_parsed = \"<|endoftext|>\".join(tweets_10)\n",
    "Path(\"tweets.txt\").write_text(tweets_parsed, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcript parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "909321"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('original_speeches.txt', encoding='UTF-8') as f:\n",
    "    speech = f.readlines()\n",
    "speech = [line.strip() for line in speech if 'SPEECH' not in line]\n",
    "speech = [line for line in speech if line != '']\n",
    "speech_parsed = \"<|endoftext|>\".join(speech)\n",
    "Path(\"speeches.txt\").write_text(speech_parsed, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine tweets.txt and speeches.txt into dataset.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweets.txt', encoding='utf-8') as f:\n",
    "    tweets = f.read()\n",
    "with open('speeches.txt', encoding='utf-8') as f:\n",
    "    speeches = f.read()\n",
    "data = speeches + tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters in dataset: 3832095\n"
     ]
    }
   ],
   "source": [
    "print('Total characters in dataset:', len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3832095"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(\"dataset.txt\").write_text(data, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
