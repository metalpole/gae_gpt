{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Combine original datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets: 4066\n"
     ]
    }
   ],
   "source": [
    "with open('master_2019.txt', 'r', encoding='utf-8') as f:\n",
    "    data_2019 = f.readlines()\n",
    "    tweets_2019 = [tweet.rstrip('\\n') for tweet in data_2019[1:]]\n",
    "    # Remove tweets with 'Thank you'\n",
    "    tweets_2019 = [tweet for tweet in tweets_2019 if 'Thank you' not in tweet]\n",
    "    print(\"No. of tweets:\", len(tweets_2019))\n",
    "    \n",
    "del data_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets: 2281\n"
     ]
    }
   ],
   "source": [
    "with open('master_2018.json') as f:\n",
    "    data_2018 = json.load(f)\n",
    "    \n",
    "tweets_2018 = []\n",
    "for tweet in reversed(data_2018):\n",
    "    if tweet['retweeted']==False:\n",
    "        if 'android' in tweet['source']:\n",
    "            try:\n",
    "                tweets_2018.append(tweet['full_text'])\n",
    "            except:\n",
    "                tweets_2018.append(tweet['text'])\n",
    "        elif 'iphone' in tweet['source']:\n",
    "            try:\n",
    "                if 'Thank you' not in tweet['text']:\n",
    "                    tweets_2018.append(tweet['text'])\n",
    "            except:\n",
    "                if 'Thank you' not in tweet['full_text']:\n",
    "                    tweets_2018.append(tweet['full_text'])\n",
    "            \n",
    "del data_2018\n",
    "print(\"No. of tweets:\", len(tweets_2018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets: 2281\n"
     ]
    }
   ],
   "source": [
    "with open('master_2017.json') as f:\n",
    "    data_2017 = json.load(f)\n",
    "    \n",
    "tweets_2017 = []\n",
    "for tweet in reversed(data_2017):\n",
    "    if tweet['retweeted']==False:\n",
    "        if 'android' in tweet['source']:\n",
    "            try:\n",
    "                tweets_2017.append(tweet['full_text'])\n",
    "            except:\n",
    "                tweets_2017.append(tweet['text'])\n",
    "        elif 'iphone' in tweet['source']:\n",
    "            try:\n",
    "                if 'Thank you' not in tweet['text']:\n",
    "                    tweets_2017.append(tweet['text'])\n",
    "            except:\n",
    "                if 'Thank you' not in tweet['full_text']:\n",
    "                    tweets_2017.append(tweet['full_text'])\n",
    "del data_2017\n",
    "print(\"No. of tweets:\", len(tweets_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets: 3361\n"
     ]
    }
   ],
   "source": [
    "with open('master_2016.json') as f:\n",
    "    data_2016 = json.load(f)\n",
    "    \n",
    "tweets_2016 = []\n",
    "for tweet in reversed(data_2016):\n",
    "    if tweet['retweeted']==False:\n",
    "        if 'android' in tweet['source']:\n",
    "            try:\n",
    "                tweets_2016.append(tweet['full_text'])\n",
    "            except:\n",
    "                tweets_2016.append(tweet['text'])\n",
    "        elif 'iphone' in tweet['source']:\n",
    "            try:\n",
    "                if 'Thank you' not in tweet['text']:\n",
    "                    tweets_2016.append(tweet['text'])\n",
    "            except:\n",
    "                if 'Thank you' not in tweet['full_text']:\n",
    "                    tweets_2016.append(tweet['full_text'])\n",
    "            \n",
    "del data_2016\n",
    "print(\"No. of tweets:\", len(tweets_2016))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets: 7124\n"
     ]
    }
   ],
   "source": [
    "with open('master_2015.json') as f:\n",
    "    data_2015 = json.load(f)\n",
    "    \n",
    "tweets_2015 = []\n",
    "for tweet in reversed(data_2015):\n",
    "    if (tweet['retweeted']==False) and ('iphone' not in tweet['source']):\n",
    "        try:\n",
    "            tweets_2015.append(tweet['full_text'])\n",
    "        except:\n",
    "            tweets_2015.append(tweet['text'])\n",
    "            \n",
    "del data_2015\n",
    "print(\"No. of tweets:\", len(tweets_2015))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets: 5781\n"
     ]
    }
   ],
   "source": [
    "with open('master_2014.json') as f:\n",
    "    data_2014 = json.load(f)\n",
    "    \n",
    "tweets_2014 = []\n",
    "for tweet in reversed(data_2014):\n",
    "    if (tweet['retweeted']==False) and ('iphone' not in tweet['source']):\n",
    "        try:\n",
    "            tweets_2014.append(tweet['full_text'])\n",
    "        except:\n",
    "            tweets_2014.append(tweet['text'])\n",
    "            \n",
    "del data_2014\n",
    "print(\"No. of tweets:\", len(tweets_2014))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets: 8135\n"
     ]
    }
   ],
   "source": [
    "with open('master_2013.json') as f:\n",
    "    data_2013 = json.load(f)\n",
    "    \n",
    "tweets_2013 = []\n",
    "for tweet in reversed(data_2013):\n",
    "    if tweet['retweeted']==False:\n",
    "        try:\n",
    "            tweets_2013.append(tweet['full_text'])\n",
    "        except:\n",
    "            tweets_2013.append(tweet['text'])\n",
    "            \n",
    "del data_2013\n",
    "print(\"No. of tweets:\", len(tweets_2013))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets: 3529\n"
     ]
    }
   ],
   "source": [
    "with open('master_2012.json') as f:\n",
    "    data_2012 = json.load(f)\n",
    "    \n",
    "tweets_2012 = []\n",
    "for tweet in reversed(data_2012):\n",
    "    if tweet['retweeted']==False:\n",
    "        try:\n",
    "            tweets_2012.append(tweet['full_text'])\n",
    "        except:\n",
    "            tweets_2012.append(tweet['text'])\n",
    "            \n",
    "del data_2012\n",
    "print(\"No. of tweets:\", len(tweets_2012))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets: 774\n"
     ]
    }
   ],
   "source": [
    "with open('master_2011.json') as f:\n",
    "    data_2011 = json.load(f)\n",
    "    \n",
    "tweets_2011 = []\n",
    "for tweet in reversed(data_2011):\n",
    "    if tweet['retweeted']==False:\n",
    "        try:\n",
    "            tweets_2011.append(tweet['full_text'])\n",
    "        except:\n",
    "            tweets_2011.append(tweet['text'])\n",
    "            \n",
    "del data_2011\n",
    "print(\"No. of tweets:\", len(tweets_2011))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets: 142\n"
     ]
    }
   ],
   "source": [
    "with open('master_2010.json') as f:\n",
    "    data_2010 = json.load(f)\n",
    "    \n",
    "tweets_2010 = []\n",
    "for tweet in reversed(data_2010):\n",
    "    if tweet['retweeted']==False:\n",
    "        try:\n",
    "            tweets_2010.append(tweet['full_text'])\n",
    "        except:\n",
    "            tweets_2010.append(tweet['text'])\n",
    "            \n",
    "del data_2010\n",
    "print(\"No. of tweets:\", len(tweets_2010))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets: 56\n"
     ]
    }
   ],
   "source": [
    "with open('master_2009.json') as f:\n",
    "    data_2009 = json.load(f)\n",
    "    \n",
    "tweets_2009 = []\n",
    "for tweet in reversed(data_2009):\n",
    "    if tweet['retweeted']==False:\n",
    "        try:\n",
    "            tweets_2009.append(tweet['full_text'])\n",
    "        except:\n",
    "            tweets_2009.append(tweet['text'])\n",
    "            \n",
    "del data_2009\n",
    "print(\"No. of tweets:\", len(tweets_2009))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tweets = tweets_2009 + tweets_2010 + tweets_2011 + tweets_2012 + tweets_2013 + tweets_2014 + tweets_2015 + tweets_2016 + tweets_2017 + tweets_2018 + tweets_2019\n",
    "tweets = [tweet for tweet in tweets if 'RT @' not in tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36699"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('tweets.json', 'w') as outfile:\n",
    "    json.dump(tweets, outfile)\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweets.json') as f:\n",
    "    tweets = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of tweets with announcement words: 3450\n",
      "No. of manual RTs: 6015\n",
      "Dataset: 23302\n"
     ]
    }
   ],
   "source": [
    "# Convert &amp to &\n",
    "tweets_2 = []\n",
    "for tweet in tweets:\n",
    "    if '&amp' in tweet:\n",
    "        tweets_2.append(''.join(tweet.split('amp;')))\n",
    "    else:\n",
    "        tweets_2.append(tweet)\n",
    "        \n",
    "# convert \\u201 to '\n",
    "tweets_3 = []\n",
    "for tweet in tweets_2:\n",
    "    if '\\\\u2013' in tweet:\n",
    "        tweets_3.append('\\''.join(tweet.split('\\\\u2013')))\n",
    "    if '\\\\u2015' in tweet:\n",
    "        tweets_3.append('\\''.join(tweet.split('\\\\u2015')))\n",
    "    if '\\\\u2018' in tweet:\n",
    "        tweets_3.append('\\''.join(tweet.split('\\\\u2018')))\n",
    "    if '\\\\u2019' in tweet:\n",
    "        tweets_3.append('\\''.join(tweet.split('\\\\u2019')))\n",
    "    else:\n",
    "        tweets_3.append(tweet)\n",
    "        \n",
    "# Get rid of URLs\n",
    "tweets_4 = []\n",
    "for tweet in tweets_3:\n",
    "    if 'http' in tweet:\n",
    "        tweets_4.append(''.join(re.split(r'http\\S+', tweet)))\n",
    "    else:\n",
    "        tweets_4.append(tweet)\n",
    "        \n",
    "# Get rid of '[VIDEO]', 'Video'\n",
    "tweets_5 = [tweet for tweet in tweets_4 if ('[VIDEO]' not in tweet) and ('Video' not in tweet)]\n",
    "        \n",
    "# Get rid of tweets with more than 3 twitter handles (1247)\n",
    "tweets_6 = []\n",
    "for tweet in tweets_5:\n",
    "    if tweet.count('@') <= 2:\n",
    "        tweets_6.append(tweet)\n",
    "\n",
    "# Get rid of tweets for event announcements with words like 'join', 'Join', 'tomorrow' and hashtags\n",
    "count_announcements = 0\n",
    "tweets_7 = []\n",
    "for tweet in tweets_6:\n",
    "    if ('join' in tweet) or ('Join' in tweet) or ('tomorrow' in tweet) or ('Tune' in tweet) or ('I\\'ll be on' in tweet) or \\\n",
    "    ('#Take' in tweet) or ('Just arrive' in tweet) or ('#trump' in tweet) or (' EST ' in tweet) or ('AM ' in tweet) or \\\n",
    "    ('My interview' in tweet) or ('trump2016' in tweet) or ('My @FoxNews' in tweet) or ('I will be on' in tweet) or \\\n",
    "    ('makeamerica' in tweet) or ('#INP' in tweet) or ('I will be interviewed' in tweet) or ('I will be going' in tweet) or \\\n",
    "    ('I will be making' in tweet) or ('I will be in' in tweet) or ('I will be li' in tweet) or ('I will be do' in tweet) or \\\n",
    "    ('#TrumpTu' in tweet) or ('#TrumpTr' in tweet) or ('Thanks.' in tweet) or ('Thanks!' in tweet) or ('thanks!' in tweet) or \\\n",
    "    ('thanks.' in tweet) or ('Via' in tweet) or ('via' in tweet) or ('P.M' in tweet) or ('A.M' in tweet) or \\\n",
    "    ('Will be on ' in tweet) or ('Will be interv' in tweet) or ('#El' in tweet) or ('#IC' in tweet) or ('#IA' in tweet) or \\\n",
    "    ('Looking' in tweet) or ('Watch m' in tweet):\n",
    "        count_announcements+=1\n",
    "    else:\n",
    "        tweets_7.append(tweet)\n",
    "print('No. of tweets with announcement words:', count_announcements)\n",
    "\n",
    "# Get rid of manual retweets @XXX: @realDonaldTrump\n",
    "manual_retweets = 0\n",
    "tweets_8 = []\n",
    "for tweet in tweets_7:\n",
    "    try:\n",
    "        re.search(r'@\\S+:\\s@\\S+', tweet).group(0)\n",
    "        manual_retweets+=1\n",
    "    except:\n",
    "        tweets_8.append(tweet)\n",
    "        \n",
    "# Get rid of manual retweets \"@XXX: \"\n",
    "tweets_9 = []\n",
    "for tweet in tweets_8:\n",
    "    try:\n",
    "        re.search(r'\\\"@\\S+:\\s', tweet).group(0)\n",
    "        manual_retweets+=1\n",
    "    except:\n",
    "        tweets_9.append(tweet)\n",
    "print('No. of manual RTs:', manual_retweets)\n",
    "\n",
    "\n",
    "print('Dataset:', len(tweets_9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3079912"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_parsed = \"<|endoftext|>\".join(tweets_9)\n",
    "Path(\"tweets.txt\").write_text(tweets_parsed, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
